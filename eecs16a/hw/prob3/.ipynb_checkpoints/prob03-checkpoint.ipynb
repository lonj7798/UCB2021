{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 16A: Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Filtering Out The Troll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import wave as wv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "from IPython.display import Audio\n",
    "from scipy import io\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "# For this to work make sure to download m1.wav and m2.wav to the same location as this jupyter notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sound_file_1 = \"m1.wav\"\n",
    "sound_file_2 = \"m2.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen to the recording of the first microphone (it can take some time to load the sound file). Run the cell below, then press the play button to listen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"m1.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio(url=\"m1.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the recording of the second microphone (it can take some time to load the sound file). Run the cell below, then press the play button to listen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"m2.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Audio(url=\"m2.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the first recording to the variable `corrupt1` and the second recording to `corrupt2`. Treat `corrupt1` and `corrupt2` as the two sound recordings picked up by microphone 1 and microphone 2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate1, corrupt1 = scipy.io.wavfile.read(\"m1.wav\")\n",
    "rate2, corrupt2 = scipy.io.wavfile.read(\"m2.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the weights of the two recordings to get the clean speech.\n",
    "\n",
    "Note: The square root of a number $a$ can be written as ```np.sqrt(a)``` in IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the weights c (recording 1) and k (recording 2)\n",
    "c = \n",
    "k ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted combination of the two recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = c * corrupt1 + k * corrupt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's listen to the resulting sound file (make sure your speaker's volume is not very high, the sound may be loud if things go wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=a, rate=rate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Image Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Visualization for Part (a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plotting Setup'''\n",
    "''' Please run this cell before moving to the following cells'''\n",
    "def transform_the_polygon_1(polygon, R):    \n",
    "    transformed_polygon = []\n",
    "    for point in polygon:\n",
    "        transformed_point = np.dot(R, point)\n",
    "        transformed_polygon.append(transformed_point)\n",
    "    return transformed_polygon\n",
    "def transform_the_polygon_2(polygon, t):    \n",
    "    transformed_polygon = []\n",
    "    for point in polygon:\n",
    "        transformed_point = point+t\n",
    "        transformed_polygon.append(transformed_point)\n",
    "    return transformed_polygon\n",
    "def plot_the_polygon(polygon, title):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(111, xlim = [-5, 5], ylim = [-5, 5])\n",
    "    ax.grid(True)\n",
    "    ax.axhline(y=0, color='k', linestyle = '--', linewidth = 1)\n",
    "    ax.axvline(x=0, color='k', linestyle = '--', linewidth = 1)\n",
    "    for i in range(len(polygon) - 1):\n",
    "        ax.plot([polygon[i][0], polygon[i+1][0]],\n",
    "                [polygon[i][1], polygon[i+1][1]], linewidth=2, linestyle='dashed')\n",
    "        arrow = mpatches.FancyArrowPatch((0, 0), (polygon[i][0], polygon[i][1]), mutation_scale=15, ec ='blue')\n",
    "        ax.add_patch(arrow)\n",
    "    ax.plot([polygon[i+1][0], polygon[0][0]], [polygon[i+1][1], polygon[0][1]], linewidth=2, linestyle='dashed')\n",
    "    arrow = mpatches.FancyArrowPatch((0, 0), (polygon[i+1][0], polygon[i+1][1]), mutation_scale=15, ec ='blue')\n",
    "    ax.add_patch(arrow)\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to visualize how $\\begin{bmatrix} 2 & 2 \\\\ -2 & 2 \\end{bmatrix}$ is transforming  $\\vec{u}$. We have chosen four different values of  $\\vec{u}$: $\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, $\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$, $\\begin{bmatrix} -1 \\\\ -1 \\end{bmatrix}$, and $\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$. These four vectors are plotted in the \"$\\textbf{Original Vectors}$\" plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sample_img = [np.array([1,1]), np.array([1,-1]), np.array([-1, -1]), np.array([-1,1])]\n",
    "plot_the_polygon(sample_img, 'Original Vectors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Then we transform $\\vec{u}$ with $\\begin{bmatrix} 2 & 2 \\\\ -2 & 2 \\end{bmatrix}$, i.e. we find $\\vec{v_1}=\\begin{bmatrix} 2 & 2 \\\\ -2 & 2 \\end{bmatrix}\\vec{u}$ for all four values of $\\vec{u}$. These four transformed vectors are shown in the \"$\\textbf{Step 1 Transformation}$\" plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 2],\n",
    "              [-2, 2]])\n",
    "transformed_img1 = transform_the_polygon_1(sample_img, A)\n",
    "plot_the_polygon(transformed_img1, 'Step 1 Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Now we visualize how  addition of $\\vec{w}=\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$ geometrically transforms  $\\vec{v_1}$. We utilize the four different values of $\\vec{v_1}$ from Step 1.\n",
    "\n",
    "Then we find $\\vec{v}=\\vec{v_1}+\\vec{w}$ for all four values of $\\vec{v_1}$. These four transformed vectors are shown in the \"$\\textbf{Step 2 Transformation}$\" plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([0,1])\n",
    "transformed_img2 = transform_the_polygon_2(transformed_img1, w)\n",
    "plot_the_polygon(transformed_img2, 'Step 2 Transformation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the notebook continues the image stiching problem. Be sure to have the \"figures\" folder in the same directory.  as the notebook. The folder should have the following files:\n",
    "\n",
    "    Berkeley_banner_1.jpg\n",
    "    Berkeley_banner_2.jpg\n",
    "    stacked_pieces.jpg\n",
    "    lefthalfpic.jpg\n",
    "    righthalfpic.jpg\n",
    "    \n",
    "Note: This structure is also present in the provided HW3 zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next block of code before proceeding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy import pi, cos, exp, sin\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "#loading images\n",
    "image1=mpimg.imread('figures/Berkeley_banner_1.jpg')\n",
    "image1=image1/255.0\n",
    "image2=mpimg.imread('figures/Berkeley_banner_2.jpg')\n",
    "image2=image2/255.0\n",
    "image_stack=mpimg.imread('figures/stacked_pieces.jpg')\n",
    "image_stack=image_stack/255.0\n",
    "\n",
    "\n",
    "image1_marked=mpimg.imread('figures/lefthalfpic.jpg')\n",
    "image1_marked=image1_marked/255.0\n",
    "image2_marked=mpimg.imread('figures/righthalfpic.jpg')\n",
    "image2_marked=image2_marked/255.0\n",
    "\n",
    "def euclidean_transform_2to1(transform_mat,translation,image,position,LL,UL):\n",
    "    new_position=np.round(transform_mat.dot(position)+translation)\n",
    "    new_position=new_position.astype(int)\n",
    "\n",
    "    \n",
    "    if (new_position>=LL).all() and (new_position<UL).all():\n",
    "        values=image[new_position[0][0],new_position[1][0],:]\n",
    "    else:\n",
    "        values=np.array([2.0,2.0,2.0])\n",
    "    \n",
    "    return values\n",
    "\n",
    "def euclidean_transform_1to2(transform_mat,translation,image,position,LL,UL):\n",
    "    transform_mat_inv=np.linalg.inv(transform_mat)\n",
    "    new_position=np.round(transform_mat_inv.dot(position-translation))\n",
    "    new_position=new_position.astype(int)\n",
    "    \n",
    "    if (new_position>=LL).all() and (new_position<UL).all():\n",
    "        values=image[new_position[0][0],new_position[1][0],:]\n",
    "    else:\n",
    "        values=np.array([2.0,2.0,2.0])\n",
    "    \n",
    "    return values\n",
    "\n",
    "def solve(A,b):\n",
    "    try:\n",
    "        z = np.linalg.solve(A,b)\n",
    "    except:\n",
    "        raise ValueError('Rows are not linearly independent. Cannot solve system of linear equations uniquely. :)')\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will stick to a simple example and just consider stitching two images (if you can stitch two pictures, then you could conceivably stitch more by applying the same technique over and over again).\n",
    "\n",
    "Daniel decided to take an amazing picture of the Campanile overlooking the bay. Unfortunately, the field of view of his camera was not large enough to capture the entire scene, so he decided to take two pictues and stitch them together. \n",
    "\n",
    "The next block will display the two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "worksheet-0"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,40))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.imshow(image1)\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.imshow(image2)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.imshow(image_stack)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you apply Marcela's algorithm on the two images you get the following result (run the next block):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,30))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.imshow(image1_marked)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.imshow(image2_marked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see Marcela's algorithm was able to find four common points between the two images. These points expressed in the coordinates of the first image and second image are\n",
    "\n",
    "$\\begin{align} \n",
    "&&\\vec{p_1}=\\begin{bmatrix} 200 \\\\ 700 \\end{bmatrix}\n",
    "&&\\vec{p_2}=\\begin{bmatrix} 310 \\\\ 620 \\end{bmatrix} \n",
    "&&\\vec{p_3}=\\begin{bmatrix} 390 \\\\ 660 \\end{bmatrix}\n",
    "&&\\vec{p_4}=\\begin{bmatrix} 460 \\\\ 630 \\end{bmatrix}\\\\\n",
    "&&\\vec{q_1}=\\begin{bmatrix} 162.2976 \\\\ 565.8862 \\end{bmatrix}\n",
    "&&\\vec{q_2}=\\begin{bmatrix} 285.4283 \\\\ 458.7469 \\end{bmatrix} \n",
    "&&\\vec{q_3}=\\begin{bmatrix} 385.2465 \\\\ 498.1973 \\end{bmatrix}\n",
    "&&\\vec{q_4}=\\begin{bmatrix} 465.7892 \\\\ 455.0132 \\end{bmatrix}\n",
    "\\end{align}$\n",
    "\n",
    "It should be noted that in relation to the image the positive x-axis is down and the positive y-axis is right. This will have no bearing as to how you solve the problem, however it helps in interpreting what the numbers mean relative to the image you are seeing.\n",
    "\n",
    "Using the points determine the parameters $r_{xx},r_{xy},r_{yx},r_{yy},t_x,t_y$ that map the points from the first image to the points in the second image by solving an appropriate system of equations. Hint: you do not need all the points to recover the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the following is a general template for solving for 6 unknowns from 6 equations represented as Az = b.\n",
    "# You do not have to use the following code exactly. \n",
    "# All you need to do is to find parameters r_xx, r_xy, r_yx, r_yy, t_x, t_y. \n",
    "# If you prefer finding them another way it is fine.\n",
    "\n",
    "# fill in the entries\n",
    "A = np.array([[?,?,?,?,?,?],\n",
    "              [?,?,?,?,?,?],\n",
    "              [?,?,?,?,?,?],\n",
    "              [?,?,?,?,?,?],\n",
    "              [?,?,?,?,?,?],\n",
    "              [?,?,?,?,?,?]])\n",
    "\n",
    "# fill in the entries\n",
    "b = np.array([[?],[?],[?],[?],[?],[?]])\n",
    "\n",
    "A = A.astype(float)\n",
    "b = b.astype(float)\n",
    "\n",
    "# solve the linear system for the coefficiens\n",
    "z = solve(A,b)\n",
    "\n",
    "#Parameters for our transformation\n",
    "r_xx = z[0,0]\n",
    "r_xy = z[1,0]\n",
    "r_yx = z[2,0]\n",
    "r_yy = z[3,0]\n",
    "t_x  = z[4,0]\n",
    "t_y  = z[5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_xx,r_xy, r_yx,r_yy, t_x,t_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitch the images using the transformation you found by running the code below.\n",
    "\n",
    "### Note that it takes about 40 seconds for the block to finish running on a modern laptop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix_transform=np.array([[r_xx,r_xy],[r_yx,r_yy]])\n",
    "translation=np.array([t_x,t_y])\n",
    "\n",
    "#Creating image canvas (the image will be constructed on this)\n",
    "num_row,num_col,blah=image1.shape\n",
    "image_rec=1.0*np.ones((int(num_row),int(num_col),3))\n",
    "\n",
    "#Reconstructing the original image\n",
    "\n",
    "LL=np.array([[0],[0]]) #lower limit on image domain\n",
    "UL=np.array([[num_row],[num_col]]) #upper limit on image domain\n",
    "\n",
    "for row in range(0,int(num_row)):\n",
    "    for col in range(0,int(num_col)):\n",
    "        #notice that the position is in terms of x and y, so the c  \n",
    "        position=np.array([[row],[col]])       \n",
    "        if image1[row,col,0] > 0.995 and image1[row,col,1] > 0.995 and image1[row,col,2] > 0.995:\n",
    "            temp = euclidean_transform_2to1(matrix_transform,translation,image2,position,LL,UL)\n",
    "            image_rec[row,col,:] = temp\n",
    "        else:\n",
    "            image_rec[row,col,:] = image1[row,col,:]\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image_rec)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "name": "graphs_for_SOE.ipynb",
  "nteract": {
   "version": "0.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
