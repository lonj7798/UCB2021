{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Lab 3: Multipixel Scanning\n",
    "\n",
    "## EECS 16A: Designing Information Devices and Systems I, Spring 2020\n",
    "\n",
    "<!-- Any problems with lab deployment? Send an e-mail to Angie: angie.wang@eecs.berkeley.edu -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "\n",
    "#### [Generating Multipixel Scanning Matrices](#matrixGenIntro)\n",
    "* [Imaging Mask Matrix Practice](#simpleMatrixGen)\n",
    "* [Generating a Random Binary Mask Matrix](#randomBinaryMatrixGen)\n",
    "    \n",
    "#### [Imaging Simulator](#simulatorIntro)\n",
    "* [Constructing an Ideal Sensor Model](#idealSensor)\n",
    "* [Image Reconstruction Using the Ideal Sensor Model + Matrix Inverse](#idealReconstruction)\n",
    "* [Handling System Non-Idealities](#nonidealities)\n",
    "    * [Noise *(Why So Grainy? â˜¹)*](#noiseSimulation)\n",
    "    * [Eigenanalysis & the Robustness of Inverse-Based Reconstruction](#conditionNum)\n",
    "    * [Prepping for Real Imaging: Intro to Non-Linearity *(Why Everyone Wants to Own an HDR Camera)*](#nonlinearityIntro)\n",
    "\n",
    "#### [Hardware Setup](#breadboardSetup)\n",
    "\n",
    "#### [Real Multipixel Imaging](#realImaging)\n",
    "\n",
    "#### [Taste for the Future *(Advanced Techniques)*](#omp)\n",
    "<!-- * [Least Squares Reconstruction](#leastSquares) -->\n",
    "* [Compressed Sensing Magic (Orthogonal Matching Pursuit)](#omp)\n",
    "\n",
    "#### [[Delving Further Into Non-Idealities]](#nonlinearitySimulation)\n",
    "* [Non-Linearity, Unabridged](#nonlinearitySimulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This week, you will experiment with imaging methods that illuminate *multiple pixels* at a time. The multipixel illumination patterns displayed by the projector will come from a random binary matrix that you will generate. Before performing real imaging with the projector and light sensor (phototransistor) circuit, you will first step through a simulation procedure that helps you understand how multipixel imaging works (with an encryption-y spin). You will get a little taste of \"practical engineering\" (i.e. why translating theory into practice isn't as easy as it looks). After that, you'll apply these insights to real multipixel imaging, and then see a cool \"trick of the trade\" that allows you to more quickly image your drawing and get a robust result!\n",
    "\n",
    "*Note: A lot of the code to complete this lab will be provided for you to run. However, looking over the code to try to understand what it does is **highly encouraged**. Additionally, we will be writing **functions** to enable multiple parts of this lab to reuse the same code with minimal copy + pasting.*\n",
    "\n",
    "**<span style = \"color: red\">Run the following code block to get access to several pre-written functions and helper libraries.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'matrixGenIntro'><span style = \"color: blue\">Generating Multipixel Scanning Matrices</span></a>\n",
    "\n",
    "**Note: This lab will use 0 indexing, as it makes the most sense in Python.**\n",
    "\n",
    "Recall that we can define our imaging system by the following mathematical model:\n",
    "\n",
    "$$ H \\vec{i} = \\vec{s} $$ \n",
    "\n",
    "$H$ is the imaging mask matrix, $\\vec{i}$ is our image in column vector form, and $\\vec{s}$ is the sensor reading column vector. \n",
    "\n",
    "In Imaging 2, we explored scanning our image one pixel at a time, where each row of our imaging mask matrix, $H$, corresponded to one scan of our image. This meant that scanning an image with $n$ pixels would require an $H$ with $n$ rows, so that the image could then be scanned exactly $n$ times (once per pixel). As an example, for a 2x2 image, $H$ would need exactly 4 rows (one for each mask), and we would make 4 scans.\n",
    "\n",
    "Our first goal this week is to reconstruct an $n$ pixel image by illuminating pixels more than once, while still scanning the image exactly $n$ times, just like in single pixel scanning. But how can we illuminate various pixels in an example 2x2 image more than once while using only 4 scans and 4 corresponding imaging masks? The solution is to illuminate more than one pixel per mask, which motivates the question: how does one choose which pixels to illuminate with each mask?\n",
    "\n",
    "Begin by assigning each gray-scale pixel value in the 2x2 image to a variable, $iv_{ij}$, where $i$ is the row and $j$ is the column associated with the pixel location. <br/><br/>\n",
    "\n",
    "<center>\n",
    "**2x2 Image**\n",
    "<img src=\"images/img_4x4.png\" align=\"center\" style=\"height:100px\" />\n",
    "</center>\n",
    "\n",
    "<!--\n",
    "In matrix form, the 2x2 image will look like this:\n",
    "$$\\begin{bmatrix} iv_{00} & iv_{01} \\\\ iv_{10} & iv_{11} \\end{bmatrix}$$\n",
    "-->\n",
    "\n",
    "In our mathematical model above, we represent the 2x2 image as the 1D column vector: \n",
    "\n",
    "$$\\vec{i} = \\begin{bmatrix} iv_{00} \\\\ iv_{01} \\\\ iv_{10} \\\\ iv_{11} \\end{bmatrix}$$\n",
    "\n",
    "Likewise, the sensor reading column vector is represented as:\n",
    "\n",
    "$$\\vec{s} = \\begin{bmatrix} sr_0 \\\\ sr_1 \\\\ sr_2 \\\\ sr_3 \\end{bmatrix}$$\n",
    "\n",
    "Where the sensor reading from the $k$th mask is $sr_k$. In the example above, the sensor reading from the 0th mask (remember, zero indexing) is $sr_0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the relationship between the mask matrix $H$ (with per-row imaging masks $H_k$), the image vector $\\vec{i}$, and the sensor reading vector $\\vec{s}$, we provide you with this **Example System of Linear Equations:**\n",
    "\n",
    "\\begin{equation} \n",
    "iv_{00} = sr_0 \\\\\n",
    "iv_{00} + iv_{01} = sr_1 \\\\\n",
    "iv_{00} + iv_{10} = sr_2 \\\\\n",
    "iv_{01} + iv_{10} + iv_{11} = sr_3\n",
    "\\end{equation}\n",
    "\n",
    "**<span style = \"color: red\">*IMPORTANT*: The `Lab 3 System of Equations` (which you will encounter later in the lab) and this `Example System of Linear Equations` are not at all related. Use the Lab 3 System of Equations for all parts of the lab that require it. The Example System of Linear Equations should only be used as a reference in this section.</span>**\n",
    "\n",
    "How would you represent these equations in terms of matrix vector multiplication? Remember, the image vector $\\vec{i}$ and sensor reading vector $\\vec{s}$ are both 1D column vectors, but the imaging masks should be in matrix form ($H$), as illustrated below. <br/><br/>\n",
    "\n",
    "<center>\n",
    "**Imaging Mask Matrix $H$ for the Example System of Linear Equations**\n",
    "<img src=\"images/mask_sample_4x4.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Each matrix element $H_{kl}$, where $k$ is its row and $l$ is its column, takes on one of two possible values: **white = 1** and **black = 0**.  \n",
    "\n",
    "Recall that we *reshape* the $n$-element rows $H_k$ of the mask matrix into the masks (Mask $k$) themselves. To make sense of the $H$ matrix, it is helpful to look at each mask individually. As illustrated below, the 0th row of the example mask matrix will be reshaped into Mask 0 (see below) displayed by the projector. <br/><br/>\n",
    "\n",
    "<center>\n",
    "**Individual Masks for the Example System of Linear Equations**\n",
    "<img src=\"images/H_4x4_split.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Now we can see that \n",
    "\n",
    "$$H_k \\vec{i} = sr_k$$ \n",
    "\n",
    "represents a single equation in the system of equations. For example, the only term on the left hand side of the top equation is $iv_{00}$, which corresponds to the upper left pixel of the 2x2 image. This results from the fact that the upper left pixel of Mask 0 ($H_{00}$) is turned \"on\", while all other pixels of Mask 0 are \"off\", i.e.:\n",
    "\n",
    "$$\\begin{bmatrix} 1 & 0 & 0 & 0 \\end{bmatrix} \\begin{bmatrix} iv_{00} \\\\ iv_{01} \\\\ iv_{10} \\\\ iv_{11} \\end{bmatrix} = sr_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'simpleMatrixGen'><span style = \"color: blue\">Imaging Mask Matrix Practice</span></a>\n",
    "\n",
    "Now that we have an understanding of how to approach multipixel scanning, let's test our approach on a new system of equations:\n",
    "\n",
    "<center>\n",
    "**Lab 3 System of Equations**\n",
    "\n",
    "$$iv_{00} + iv_{01} + iv_{10} = sr_0$$\n",
    "$$iv_{00} + iv_{11} = sr_1$$\n",
    "$$iv_{01} + iv_{11} = sr_2$$\n",
    "$$iv_{10} + iv_{11} = sr_3$$\n",
    "\n",
    "**<span style=\"color: red\">For a 2x2 image represented by $\\vec{i}$, create the matrix `H` such that $ H \\vec{i} = \\vec{s} $ represents the `Lab 3 System of Equations` above.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Create H (4x4) for the Lab 3 System of Equations --------------------\n",
    "H_new = # YOUR CODE HERE\n",
    "\n",
    "# Show H\n",
    "plt.imshow(H_new, cmap = 'gray', interpolation = 'nearest')\n",
    "plt.title('4x4 H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we will *reshape* rows $H_k$ of the mask matrix, $H$, into the individual masks themselves. \n",
    "\n",
    "**<span style=\"color: red\">You will help to write a function `showMasks` that enables you to iterate through the 4 individual masks and display them as 2x2 images (1 TODO). Double check that the generated masks make sense visually and have the expected number of illuminated pixels. The `showMasks` function will be reused later.</span>**\n",
    "\n",
    "*Hint: Reference your code from the part of Imaging 2 where you checked to make sure that the scanning matrix was producing the correct pattern by displaying each of the individual masks. You might want to check out the command `np.reshape`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "#  `H`: Mask matrix\n",
    "#  `X`: Image width\n",
    "#  `Y`: Image height\n",
    "#  `numMasksShown`: Number of individual masks to display (starting from `H` row 0)\n",
    "def showMasks(H, X, Y, numMasksShown):\n",
    "    plt.figure(figsize = (18, 12)) \n",
    "    # Use this for loop to iterate through the first `numMasksShown` rows of `H` \n",
    "    # you want to display.\n",
    "    for k in range(numMasksShown):\n",
    "        plt.subplot(numMasksShown, numMasksShown, k + 1)\n",
    "    \n",
    "        # TODO: Reshape the `k`th row of `H` to be shown in 2D --------------------\n",
    "        # Hint: `X` is the width of the image you want to observe; `Y` is its height\n",
    "        mask = # YOUR CODE HERE\n",
    "  \n",
    "        plt.imshow(mask, cmap = 'gray', interpolation = 'nearest')\n",
    "        # Title also prints number of illuminated (white) pixels per mask\n",
    "        plt.title('Mask ' + str(k) + ': ' + str(np.sum(H[k])) + ' Illuminated Pixels')\n",
    "    plt.show()\n",
    "\n",
    "# Show individual masks    \n",
    "showMasks(H = H_new, X = 2, Y = 2, numMasksShown = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'randomBinaryMatrixGen'><span style = \"color: blue\">Generating a Random Binary Mask Matrix</span></a>\n",
    "\n",
    "A 2x2 image is not very interesting to scan, so we will instead try to scan a 32x32 region. Note that this image has different dimensions compared to last week's image!\n",
    "\n",
    "**<span style=\"color: red\">To scan a 32x32 image, what dimensions must our scanning matrix $H$ have? What does the number of rows of $H$ correspond to? What does the number of columns correspond to? What do the elements in each column of $H$ represent?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style = \"color: red\">Your Answer Here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'd like to use a sufficiently interesting set of masks and you *really* don't want to be constructing such a large matrix by hand, we will provide you with a function that generates a random binary mask matrix $H$ for you, given dimensions `(X, Y)` corresponding to your image's width/height, and, as we'll go into later, a parameter for the average number of illuminated pixels per scan. The resulting matrix $H$ will consist entirely of 0's and 1's, where 1's are randomly interspersed among 0's, and each row will contain approximately **`avg1sPerRow`** (see function arguments) # of 1's. Not all rows will contain the same number of 1's!\n",
    "\n",
    "**<span style=\"color: red\">Run the `generateRandomBinaryMask` function and visually inspect that the generated `H` (with approximately 300 pixels illuminated per scan) has the right dimensions & visually looks random. `Going forward, any time a coding part of this lab references H, we're referring to this generated H.` Don't worry too much about how this function is actually implemented, but you can check out the code in `scripts/helpers.py`.</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the H mask\n",
    "H = generateRandomBinaryMask(avg1sPerRow = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">Use the `showMasks` function created earlier to show the first 4 individual masks (rows 0 to 3 of `H`) as 32x32 images.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Reuse the `showMasks` function from earlier to display the first 4 masks of H. -------\n",
    "showMasks(# YOUR CODE HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to the representation of the imaging system as taking a matrix-vector product. Recall that in the Imaging 2 lab, you reconstructed the image column vector $\\vec{i}$ from the sensor reading vector $\\vec{s}$ by applying the equation:\n",
    "\n",
    "$$\\vec{i} = H^{-1} \\vec{s}$$\n",
    "\n",
    "You used the **identity** matrix for $H$, for which the inverse $H^{-1}$ exists. In order to apply the same reconstruction method assuming a randomly generated binary $H$, you first need to make sure that your $H$ is actually invertible. \n",
    "\n",
    "**<span style=\"color: red\">How can you use Gaussian elimination to check that the square matrix $H$ is invertible? What must be true about the rows of $H$ for it to be invertible?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style = \"color: red\">Your Answer Here!</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on invertibility**\n",
    "\n",
    "Luckily, randomly generated binary matrices are *usually* invertible. However, the function we provided still double checks that the generated $H$ is indeed invertible (using an alternative method to Guassian elimination), and re-generates the matrix if it's not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id = 'simulatorIntro'><span style = \"color: blue\">Imaging Simulator</span></a>\n",
    "\n",
    "Let's take a detour before we start capturing real images with the projector. Many of you noticed during Imaging 2 that when the projector is displaying a black screen, there is still a lot of light inside the box. This is a limitation of the projector that, along with many other real system non-idealities, greatly affects our ability to reconstruct the image using the light sensor data. To understand how our imaging system operates, it's thus important to build a simulator that **accurately models** what happens when we try to capture an image, including non-idealities that we can potentially compensate for. \n",
    "\n",
    "### <a id = 'idealSensor'><span style = \"color: blue\">Constructing an Ideal Sensor Model</span></a>\n",
    "\n",
    "Let's first construct a function that emulates what we would *hope* occurs in the box. An image (represented as the column vector $\\vec{i}$) is placed in a region that can be illuminated by the projector. The projector projects a sequence of masks $H_k$ onto the image (illuminating certain pixels at a time), and the digitized light sensor output ($sr_k$, an entry of the column vector $\\vec{s}$) is read for each scan $k$.\n",
    "\n",
    "Recall that these operations can be represented by the previously defined mathematical model:\n",
    "\n",
    "$$\\vec{s} = H \\vec{i}$$ \n",
    "\n",
    "**<span style=\"color:red\"> Your first goal is to translate this ideal model into a `simulateIdealCapture` function (Fill in the TODO). Apply the function using the supplied 32x32 image of a playing card and your generated random binary matrix `H`. Display the simulated sensor readout as a 32x32 image.</span>**\n",
    "\n",
    "*Hint: Remember to use `np.dot` to do matrix multiplication.*\n",
    "\n",
    "The card you're trying to image should look like: <br/><br/>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/raw_card.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "Think about what the output sensor readings will look like. Given randomly generated masks, would you expect the output sensor readings to be remotely recognizable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs: \n",
    "#  `i2D`: 2D image you're trying to capture\n",
    "#  `H`: Mask matrix\n",
    "#  `matrixName`: Name of mask matrix (for image title)\n",
    "#  `display`: Whether to display the sensor output as a 2D image\n",
    "# Outputs:\n",
    "#  `s`: Sensor reading column vector\n",
    "def simulateIdealCapture(i2D, H, matrixName, display = True):\n",
    "    # Number of pixels in your image = `iHeight` * `iWidth`\n",
    "    iHeight = i2D.shape[0]\n",
    "    iWidth = i2D.shape[1]\n",
    "    iSize = iHeight * iWidth\n",
    "    \n",
    "    # Convert the 2D image `i2D` into a 1D column vector `i` \n",
    "    i = np.reshape(i2D, (iSize, 1))\n",
    "    \n",
    "    # TODO: Perform the matrix operation to emulate the ideal imaging system  --------------\n",
    "    s = # YOUR CODE HERE\n",
    "    \n",
    "    if (display):\n",
    "        \n",
    "        # Reshape the simulated sensor output `s` into an appropriately \n",
    "        # sized 2D matrix `s2D` and plots it\n",
    "        s2D = np.reshape(s, (iHeight, iWidth))\n",
    "        plt.imshow(s2D, cmap = 'gray', interpolation = 'nearest')\n",
    "        plt.title('Ideal Sensor Output, Using %s' % matrixName)\n",
    "        plt.show()\n",
    "    return s;\n",
    "\n",
    "# Load card image + display it\n",
    "i2D = np.load('scripts/raw_card.npy')\n",
    "plt.imshow(i2D, cmap = 'gray', interpolation = 'nearest')\n",
    "plt.title('Raw 32x32 Image of a Playing Card')\n",
    "plt.show()\n",
    "\n",
    "# Simulate the image capture step (ideal)\n",
    "s = simulateIdealCapture(i2D = i2D, H = H, matrixName = 'H');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'idealReconstruction'><span style = \"color: blue\">Image Reconstruction Using the Ideal Sensor Model + Matrix Inverse</span></a>\n",
    "\n",
    "As you can see, for *multipixel imaging*, the sensor output does not resemble the original image in any way. By applying the randomly generated mask matrix $H$, you've essentially encrypted the image data, making it unrecognizable to anyone who doesn't know the exact mask matrix $H$ you used (otherwise known as the encryption key).\n",
    "\n",
    "If you know the key $H$, as stated before, you can reconstruct/decrypt the desired image column vector $\\vec{i}$ from the sensor reading vector $\\vec{s}$ by essentially *undoing* what the imaging system did to the image and applying the equation:\n",
    "\n",
    "$$\\vec{i} = H^{-1} \\vec{s}$$\n",
    "\n",
    "Again, it's important that we've selected an invertible $H$. \n",
    "\n",
    "**<span style=\"color:red\">Now your job is to help write a function `idealReconstruction` (Fill in the TODO) that accepts the column vector $\\vec{s}$ and mask matrix $H$ and displays the reconstructed estimate of $\\vec{i}$ as a 2D image. Run the reconstruction function using the previously computed `s` and mask matrix `H` and verify that it worked as you expected.</span>**\n",
    "\n",
    "*Hint: Use `np.linalg.inv` to invert a matrix.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "#  `H`: Mask matrix\n",
    "#  `matrixName`: Name of mask matrix (for image title)\n",
    "#  `s`: Sensor reading column vector\n",
    "#  `X`: Image width\n",
    "#  `Y`: Image height\n",
    "def idealReconstruction(H, matrixName, s, X = 32, Y = 32, realImaging = False):\n",
    "    \n",
    "    # TODO: Perform the matrix operations required for reconstruction --------------------\n",
    "    i = # YOUR CODE HERE\n",
    "    \n",
    "    if realImaging:\n",
    "        i = noiseMassage(i, H)\n",
    "    \n",
    "    # Reshape the column vector `i` to display it as a 2D image\n",
    "    i2D = np.reshape(i, (Y, X))    \n",
    "    # We're going to exclude the top row and left-most column from display\n",
    "    plt.imshow(i2D[1:, 1:], cmap = 'gray', interpolation = 'nearest')\n",
    "    plt.title('Reconstructed Image, Using %s' % matrixName)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Run ideal reconstruction    \n",
    "idealReconstruction(H = H, matrixName = 'H', s = s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'nonidealities'><span style = \"color: blue\">Handling System Non-Idealities</span></a>\n",
    "\n",
    "The ideal reconstruction demonstrated above works great, right? Unfortunately, due to real-world non-idealities alluded to earlier, if you directly tried to image a drawing with the multipixel masks in $H$, the reconstruction would probably look terrible. A significant amount of engineering effort is focused on how to best translate theory into practice by attempting to compensate for or remove non-idealities. In the following sections, we'll look at some of the worst offenders and what we can do to improve reconstruction quality. \n",
    "\n",
    "#### <a id = 'noiseSimulation'><span style = \"color: blue\">Noise *(Why So Grainy? â˜¹)*</span></a>\n",
    "\n",
    "We will see noise again later in Module 3,--if you're really interested in modelling noise and its effects, it's covered more extensively upper division classes including EE123, EE126, EE142 -- but for now it's important to realize that both the light sensor circuit and the projector add noise that shows up in the digitized sensor output. Noise is what causes photos to look grainy or fuzzy. As an example, if your single pixel imaging system from last week happened to be very noisy (and usually, the cheaper $ the system, the noisier it is...), imaging the card from before might've produced something like: <br/><br/>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/noisy_card.png\" align=\"center\" style=\"height:200px\" />\n",
    "</center>\n",
    "\n",
    "The noisier your system, the less the resultant image will look like what you expected â˜¹.\n",
    "\n",
    "One way to make noise less problematic is to increase the number of pixels illuminated per scan. This increases the \"signal level\" (i.e. contributions from things we actually care about). At the same time, the amount of noise coming from the light sensor circuit and projector should stay mostly constant, thus improving the so-called *signal-to-noise ratio* (SNR) of our system. This is important to know when choosing `avg1sPerRow` for our random binary mask.\n",
    "\n",
    "Another way to make noise less problematic is to repeat each scan $k$ (with the same illumination pattern) many times and *average* the sensor outputs. The desired signal is always present, but the *random* error (noise) changes on each repeat scan. Thus, you can \"average out the noise\" at the expense of spending more time acquiring the image. This is actually what the Launchpad code you will use does under the hood.\n",
    "\n",
    "Generally speaking, we would like to build a sensing system that is as noise robust as possible, but what does that entail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id = 'conditionNum'><span style = \"color: blue\">Eigenanalysis & the Robustness of Inverse-Based Reconstruction</span></a>\n",
    "\n",
    "### <span style = \"color: red\">THIS SECTION IS VERY IMPORTANT. PLEASE READ CAREFULLY.</span>\n",
    "When noise is included, the mathematical model of our imaging system would look like:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} + \\vec{\\omega} +\\vec{o} $$\n",
    "\n",
    "The vector $\\vec{o}$ is a vector of all the same value, which represents an offset from extra light from the projector while it is projecting the color black. Even though black is supposed to be an absence of light, there is still a glow present from the projector that can offset our measurement by a scalar amount. This needs to be removed, but can easily be done so by measuring and subtracting it. \n",
    "\n",
    "The elements ($\\omega_k$) of the column vector $\\vec{\\omega}$ correspond to the random amounts of noise added at each measurement $sr_k$. We cannot remove noise, but we can try to prevent it.\n",
    "\n",
    "For example, you might expect your sensor readings $\\vec{s}$ to be something like \n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{s_{expected}} = \\begin{bmatrix}\n",
    "51 \\\\\n",
    "65 \\\\\n",
    "42 \\\\\n",
    "\\vdots \\\\\n",
    "32\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "But you may get something like\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{s_{reality}} = \\begin{bmatrix}\n",
    "61.2 \\\\\n",
    "76.0 \\\\\n",
    "51.7 \\\\\n",
    "\\vdots \\\\\n",
    "44.0\n",
    "\\end{bmatrix}\\;.\n",
    "\\end{equation}\n",
    "\n",
    "This means that what you are getting is really\n",
    "\n",
    "\\begin{equation}\n",
    "    \\vec{s_{reality}} = \\vec{s_{expected}} \\;+\\; \\vec{\\omega} \\;+\\; \\vec{o}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "        61.2 \\\\\n",
    "        76.0 \\\\\n",
    "        51.7 \\\\\n",
    "        \\vdots \\\\\n",
    "        44.0\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        51 \\\\\n",
    "        65 \\\\\n",
    "        42 \\\\\n",
    "        \\vdots \\\\\n",
    "        32\n",
    "    \\end{bmatrix}\n",
    "    \\;+\\;\n",
    "    \\begin{bmatrix}\n",
    "        0.2 \\\\\n",
    "        1.0 \\\\\n",
    "        -0.3 \\\\\n",
    "        \\vdots \\\\\n",
    "        2.0\n",
    "        \\end{bmatrix}\n",
    "    \\;+\\;\n",
    "    \\begin{bmatrix}\n",
    "        10 \\\\\n",
    "        10 \\\\\n",
    "        10 \\\\\n",
    "        \\vdots \\\\\n",
    "        10\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where the last two vectors are $\\vec{\\omega}$ and $\\vec{o}$\n",
    "\n",
    "As you can see, once you measure the offset, it is very easy to just subtract from your measurements. We will take care of this for you in the experimental portion of the lab (below), so you don't need to worry about it. We will ignore it in the rest of the notebook, and assume it is subtracted.\n",
    "\n",
    "From this point forward, our key equation will look like this:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} + \\vec{\\omega}$$\n",
    "\n",
    "Now we will try to reconstruct the image $\\vec{i}$ with matrix inversion $H^{-1}$:\n",
    "\n",
    "$$ H^{-1}\\vec{s} = H^{-1}H \\vec{i} + H^{-1}\\vec{\\omega}$$\n",
    "\n",
    "$$ H^{-1}\\vec{s} = \\vec{i} + H^{-1}\\vec{\\omega}$$\n",
    "\n",
    "We will call $H^-{1}\\vec{s} = \\vec{i_{est}}$ leaving us with \n",
    "$$ \\vec{i_{est}} = H^{-1} \\vec{s} = \\vec{i} + H^{-1} \\vec{\\omega} $$\n",
    "\n",
    "Remember that we were hoping to solve for just $\\vec{i}$. The additional undesired term $H^{-1} \\vec{\\omega}$ is what we call our reconstruction *error*, which results from linearly transforming the original noise vector $\\vec{\\omega}$ by $H^{-1}$. This implies that our choice of $H$ (and therefore $H^{-1}$) strongly influences how robust our overall imaging system is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build some intuition on why this is the case, recall that matrix-vector multiplication $A \\vec{x} = \\vec{b}$ linearly transforms $\\vec{x}$ into $\\vec{b}$ via scaling and rotation, as designated by $A$. Additionally, recall that the eigenvalues $\\lambda_i$ and $n$ length eigenvectors $\\vec{v_{\\lambda_i}}$ of an $n \\times n$ matrix $A$ can be found by solving for:\n",
    "\n",
    "$$A \\vec{v_{\\lambda_i}} = \\lambda_i \\vec{v_{\\lambda_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying both sides of this equation by $A^{-1}$ and dividing by $\\lambda_i$ allows us to rewrite this equation as:\n",
    "\n",
    "$$A^{-1} \\vec{v_{\\lambda_i}} = \\frac{1}{\\lambda_i} \\vec{v_{\\lambda_i}} $$ \n",
    "\n",
    "This is all good an well, but how does this relate to our task of reconstructing an image? We know that $H$, which is an $N \\times N$ matrix, is invertible, and thus we know it has at most $N$ linearly independent eigenvectors. However, we are also selecting a matrix that is also diagonalizable, so we know for a fact that our matrix $H$ has $N$ linearly independent eigenvectors. Diagonalization is not a concept you have learned yet, it will be covered in EECS16B, but for this lab, take our word that the $H$ matrix has $N$ linearly independent eigenvectors because of this property. With this, we know that the eigenvectors of $H$ form a basis for $\\mathbb{R}^N$, that is, a linearly independent set of vectors that span $\\mathbb{R}^N$. Since our noise vector exists in $\\mathbb{R}^N$, we can write it as a linear combination of the eigenvectors like so:\n",
    "\n",
    "$$\\vec{\\omega} = \\alpha_1 \\vec{v_1} + ... + \\alpha_n \\vec{v_n}$$\n",
    "\n",
    "Now if we apply $H^{-1}$ to both sides of the equation,\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = H^{-1} \\alpha_1 \\vec{v_1} + ... + H^{-1}\\alpha_n \\vec{v_n}$$\n",
    "\n",
    "Pull out the $\\alpha$ constants in front of $H^{-1}$ since scalars commute with matrices\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = \\alpha_1 H^{-1} \\vec{v_1} + ... + \\alpha_n H^{-1} \\vec{v_n}$$\n",
    "\n",
    "And we can apply the eigenvector identity shown above:\n",
    "\n",
    "$$H^{-1} \\vec{\\omega} = \\alpha_1 \\frac{1}{\\lambda_1} \\vec{v_1} + ... + \\alpha_n \\frac{1}{\\lambda_n} \\vec{v_n}$$\n",
    "\n",
    "So we can see that regardless of the scaling constants $\\alpha$, if we have very large eigenvalues of $H$ then each component of $\\vec{\\omega}$ is attenuated, and likewise if each eigenvalue is small, the noise vector will be amplified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = 'conditionNum'><span style = \"color: blue\">Graphical Interpretation</span></a>\n",
    "\n",
    "Another way we can picture this is by showing a graphical example, thinking of how $H$ is a transformation that rotates and scales vectors. In the following image, we have our ideal sensor readings, $H\\vec{i}$ and a noise vector, $\\vec{\\omega}$. After applying two different matrices, $H_1^{-1}$ and $H_2^{-1},$ we can see how each vector is transformed. Ideally we would want the $\\vec{\\omega}$ vector to be $\\vec{0}$, so the recovered image is the same as the ideal reconstruction. Adding everything together to get the final result, we have $\\vec{i}+H^{-1}\\vec{\\omega}$. Depending on the choice of $H$, the noise may end up amplified or attenuated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/2d_transform.jpg\" align=\"center\"/>\n",
    "**Visual representation of the effect of different matrices on the noise vector $\\omega$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerically, we can also see what happens to the noise with different matrices by applying them to a given noise vector. We will now introduce a special matrix that we call the \"mystery matrix.\" It has interesting properties useful in many applications. **Write the code to print out the magnitude (norm) of the noise vectors after applying the inverses of the random masking matrix and the mystery matrix.**\n",
    "\n",
    "_Hint:_ **`np.linalg.norm`** _may be useful_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates the random binary matrix\n",
    "H = generateRandomBinaryMask(avg1sPerRow = 300, plot=False)\n",
    "#Recall from the beginning of the lab that the H matrix refers to the randomH matrix.\n",
    "\n",
    "# Creates the mysteryH mystery matrix with interesting, useful properties\n",
    "mysteryH = createMysteryMatrix(shape = H.shape, plot=False)\n",
    "\n",
    "sigma = 7\n",
    "noise = np.random.normal(0, sigma, H.shape[0])\n",
    "\n",
    "#Apply mysteryH inverse to the noise vector, and then compute its norm\n",
    "mysteryNorm = # YOUR CODE HERE\n",
    "\n",
    "#Apply H inverse to the noise vector, and then compute its norm\n",
    "randomNorm = # YOUR CODE HERE\n",
    "\n",
    "print(\"Norm of the noise vector after mysteryH inverse: \", mysteryNorm)\n",
    "print(\"Norm of the noise vector after H inverse: \", randomNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which matrix amplifies the noise less?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your answer here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = 'conditionNum'><span style = \"color: blue\">Revisiting the Identity Matrix</span></a>\n",
    "We know that the identity matrix is invertible, but is it a good masking matrix? To answer that question, we need to know its eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What are the eigenvalues of the Identity matrix? What are its eigenvalues if we scale the identity matrix by a constant? What are its eigenvectors?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your answers here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the eigenvalues of the identity matrix essentially boils down to \"dimming\" the sensor readings, or making them \"brighter.\" Think about how good your scan would be if the projector only operated on 1%, or conversely 100% of its max light intensity. It is unlikely that both would give you the same quality sensor readings. **Run the next block to show the ideal image, and the noise that gets added to the image. Change the constant that scales the identity from low values like 0.1 to large values like 100 to see how the noise changes with increasing or decreasing eigenvalues. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the thing with the image + the noise image = total image.\n",
    "\n",
    "#########################\n",
    "# CHANGE THIS VARIABLE: #\n",
    "scale_factor = 1        \n",
    "#########################\n",
    "\n",
    "\n",
    "############# Dont change anything below ###################\n",
    "# Load the image\n",
    "i2D = np.load('scripts/raw_card.npy')\n",
    "M,N = i2D.shape\n",
    "\n",
    "# define the mask matrix\n",
    "H = scale_factor*np.eye(M*N)\n",
    "\n",
    "# Generate a noise vector\n",
    "sigma = 1.25\n",
    "noise = np.random.normal(0, sigma, H.shape[0])\n",
    "noise = np.reshape(noise, (M,N))\n",
    "\n",
    "# assemble noisey measurement\n",
    "s = H.dot(i2D.ravel()).reshape((M,N)) + noise\n",
    "recovered_image = np.linalg.inv(H).dot(s.ravel()).reshape((M,N))\n",
    "\n",
    "# Plot the image, noise, and image with noise\n",
    "plot_image_noise_visualization(i2D, noise, s, H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which scaling factor performs better: 0.01 or 1000? Why?</span>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your answer here!</span>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id = 'conditionNum'><span style = \"color: blue\">Comparing Scanning Matrices</span></a>\n",
    "Now let's take a look at the two matrices we will use to scan, mysteryH and randomH (referred to as H). The block of code below will show the ideal recovered image, along with the noise that gets added on top, and the total result. We will take care of generating the noise--all you have to do is tell us how much noise to add (by setting the `noise_magnitude` variable). In addition to displaying the images, the code will also print out the norm of the modified noise vector $H^{-1}\\vec{\\omega}$ so you can see quantitatively how different matrices impact the noise.\n",
    "\n",
    "[comment]: <> (**<span style=\"color:red\">First, just run the next code block so that you'll have access to `simulateCaptureWithNoise` below.</span>**)\n",
    "**<span style=\"color:red\">You will simulate the imaging system with different amounts of noise added. Run the code block below and change the noise magnitude to see how the output is affected.</span>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Change this #######\n",
    "noise_magnitude = 50.0\n",
    "#########################\n",
    "\n",
    "############# Dont change anything below ###################\n",
    "# Load the image\n",
    "i2D = np.load('scripts/raw_card.npy')\n",
    "M,N = i2D.shape\n",
    "\n",
    "# define the mask matrix\n",
    "H = generateRandomBinaryMask(avg1sPerRow = 300, plot=False)\n",
    "mysteryH = createMysteryMatrix(shape = H.shape, plot=False)\n",
    "\n",
    "# Generate a noise vector\n",
    "sigma = noise_magnitude / np.sqrt(M*N) # noise magnitude --> std dev\n",
    "noise = np.random.normal(0, sigma, H.shape[0])\n",
    "noise = np.reshape(noise, (M,N))\n",
    "\n",
    "# Plot the image, noise, and image with noise\n",
    "plot_image_noise_visualization(i2D, noise, s, H, title='Reconstruction with Random $H$')\n",
    "modified_noise_norm = np.linalg.norm(np.linalg.inv(H).dot(noise.ravel()))\n",
    "print('Norm of Hinv*w = %0.4f' % (modified_noise_norm))\n",
    "\n",
    "plot_image_noise_visualization(i2D, noise, s, mysteryH, title='Reconstruction with Mystery $H$')\n",
    "modified_noise_norm = np.linalg.norm(np.linalg.inv(mysteryH).dot(noise.ravel()))\n",
    "print('Norm of Hinv*w = %0.4f' % (modified_noise_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What noise magnitudes did you have to use for each matrix to make the image borderline unrecognizable?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your Answer Here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next section, we will examine the mystery matrix in a bit more detail. We will use the function `eigenanalysis` that plots a histogram of the magnitudes of the eigenvalues of your $H$'s and their respective inverses (x axis = magnitude bins, y axis = number of eigenvalues within the bin's magnitude range). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates the mysteryH mystery matrix with interesting, useful properties\n",
    "mysteryH = createMysteryMatrix(shape = H.shape, plot=False)\n",
    "\n",
    "# Plot the eigenvalues of both H and mysteryH\n",
    "eigenAnalysisComparison(H1 = H, matrixName1 = 'Random Binary H', H2 = mysteryH, matrixName2 = \"MysteryH\")\n",
    "\n",
    "HInv = np.linalg.inv(H)\n",
    "mysteryHInv = np.linalg.inv(mysteryH)\n",
    "\n",
    "# Plot the eigenvalues of both the inverse of H and the inverse of mysteryH\n",
    "eigenAnalysisComparison(H1 = HInv, matrixName1 = 'Inverse of Random Binary H',\\\n",
    "                        H2 = mysteryHInv, matrixName2 = 'Inverse of Mystery H')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Which of the two matrices `H` and `mysteryH` do you think is more noise robust and would result in a better reconstruction? Justify your answer using the eigenvalue histograms above.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your Answer Here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='singlePixel'></a>\n",
    "### <span style=\"color:blue\">Scanning Images</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Before moving onto real imaging, run the code block below to generate mask matrix files.</span>**\n",
    "\n",
    "Check that `packageMaskMatrix` generated the following files in your lab directory:\n",
    "* **H.npy** - Saved `H` for restoring in case you have to close out of your Jupyter notebook. \n",
    "* **H_packaged.npy** - Packaged `H` used by `capture_image.py` **(contains extra rows)**.\n",
    "* **mysteryH.npy** - Saved `mysteryH` for restoring in case you have to close out of your Jupyter notebook.\n",
    "* **mysteryH_packaged.npy** - Packaged `mysteryH` used by `capture_image.py` **(contains extra rows)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate mask matrix files    \n",
    "packageMaskMatrix(H, 'H')\n",
    "packageMaskMatrix(mysteryH, 'mysteryH')\n",
    "brightness = 90\n",
    "print(\"Done! :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:red\">**IMPORTANT**</span>: <a id ='setup'><span style = \"color: blue\">Hardware Setup</span></a>\n",
    "\n",
    "# Please follow instructions here ( [Cory 140](ee16a_imaging_setup_140.pdf) [Cory 125](ee16a_imaging_setup_125.pdf) ) *verbatim* to get consistent results. Having a good setup will make taking the picture much easier and cleaner. The box should in the top left of your station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='singlePixel'></a>\n",
    "### <span style=\"color:blue\">Single Pixel Sanity Check</span>\n",
    "\n",
    "When dealing with a complicated system, it is often useful to perform a \"sanity check\" to make sure that a simpler subset of the system is working as expected, before adding more complexity. Let's make sure that the single pixel imager from Imaging Lab 2 works. \n",
    "\n",
    "**<span style=\"color:red\">Create $H_{Single}$ for images/masks with dimensions 32x32. How many rows should it have? Note that $H_{Single}$ is the identity matrix (but it has different dimensions from $H$ in Lab 2)!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Recreate `HSingle` to scan a 32x32 image. `HSingle` is the identity matrix.\n",
    "HSingle = # YOUR CODE HERE\n",
    "\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.imshow(HSingle, cmap = 'gray', interpolation = 'nearest')\n",
    "np.save('HSingle.npy', HSingle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've saved $H_{Single}$ to a file, we need an object to take a picture of. There are index cards and markers at the GSI desk; **<span style=\"color:red\">take an index card and draw something on its blank (no lines) side. The index card should still be mostly white. Place this index card inside the box so that the projector can project onto it</span>** (see the Overview image). \n",
    "\n",
    "Tape is on the TA desk; do not take the whole dispenser, it should stay at the TA desk at all times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Double check that you've done the following before proceeding:</span>**\n",
    "\n",
    "* Upload `AnalogReadSerial` to the Launchpad.\n",
    "\n",
    "* Close the Energia Serial Monitor.\n",
    "\n",
    "* Make sure that the ambient light sensor is aimed at the center of the index card! The legs should not be touching.\n",
    "\n",
    "* Seal the imaging system inside the box to keep outside light out during scanning. If the holes for cables are too big, try to have them face a solid, unmoving object that can block out light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check again that you have closed the Energia Serial Monitor. You will not be able to scan otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">You will then run the `capture_image.py` script from the following code block that projects mask patterns from $H_{Single}$ onto your image.</span>** \n",
    "\n",
    "When running **`capture_image.py`**, a new icon shaped like a white web will appear in the taskbar. The window depicting our masks will appear on the projector's screen. *You can confirm this by looking into the box. (Don't forget to close the box when you're done checking!)*\n",
    "\n",
    "Before scanning, you will be prompted to specify the **COM port used by the Launchpad and the display associated with the projector.** \n",
    "\n",
    "**Select the COM port associated with UART1 (previously accessed in the Energia Serial Monitor and found using the Device Manager) and the 1280x720 projector screen.** Note that you want to specify the index of your choice i.e. for `2) 1280 x 720`, specify 2. **<span style=\"color:red\">Make sure that you've selected the correct COM port!</span>**\n",
    "\n",
    "`capture_image.py` iterates over the rows of the $H$ matrix you made. These rows are translated, one-by-one, into real masks projected onto the screen. Light sensor readings are taken for each mask. At the start of the scan, you'll see a series of `Loc: # Data: #` printed to the output below. `Loc` corresponds to the index $k$ of the current sensor reading (and likewise current row of H). `Data` corresponds to the actual digitized value obtained from the light sensor. This \"debug\" information is printed consecutively for the first few/last few sensor outputs. Otherwise, this info is printed when `k % 100 = 0` (every 100 scans). \n",
    "\n",
    "Don't worry about messages like `Time delta between captures in s: #`. This is printed a lot because the lab computers are kind of slow. \n",
    "\n",
    "The whole scanning process should take roughly 3 minutes. \n",
    "\n",
    "*Note: On the topic of non-idealities, our scans take so long because:*\n",
    "* We average sensor readings to improve the signal-to-noise ratio. Therefore we need to read more times.\n",
    "* As you'll learn in Module 2, capacitors take some time to charge and discharge. A capacitor acts as a \"low-pass filter.\" We used a 0.1$\\mu$F capacitor in our sensing circuit to \"smooth\" the output and suppress \"high-frequency\" noise. In order to give the capacitor time to \"settle\" (i.e. ~fully charge/discharge), we need to wait longer between scans. Otherwise, the sensor reading will also include some \"memory\" of the previous scan result, when we really want the reading to only be about the current scan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Not getting a good picture?</span>**\n",
    "\n",
    "If you selected the incorrect COM port, a lot more \"debug\" lines will be dumped. You might notice `Data: -1` or `Losing data! Consider increasing your timeout!` messages. Once you see these messages, **stop** the scan, **save** your Jupyter notebook, then **close the Jupyter notebook in your Terminal (Ctrl+C twice) and re-open it**. You'll lose any saved variables (not output images), but everything you need has been saved to a file. Rerun the following code block again, but **make sure you select the right COM port**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "\n",
    "%run capture_image.py --mask HSingle.npy --out sensor_readingsHSingle --width 32 --height 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Recreate the image from the sensor readings obtained with `HSingle`. DO NOT move on until you have an acceptable recreation. Ask for help if you need to.</span>**\n",
    "\n",
    "*Note: Because we used 32x32 masks this time, the portion of the image we're able to \"see\" is smaller.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load('sensor_readingsHSingle_100_0.npy')\n",
    "HSingle = np.load('HSingle.npy')\n",
    "\n",
    "# TODO: Create the image vector from `HSingle` and `sr`\n",
    "# Hint: Because `HSingle` is a special matrix, technically you do not need to perform any matrix operations\n",
    "iv = # YOUR CODE HERE \n",
    "\n",
    "img = np.reshape(iv, (32, 32))\n",
    "plt.imshow(img, cmap = 'gray', interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id ='realImaging'><span style = \"color: blue\">Real Multipixel Imaging</span></a>\n",
    "\n",
    "In the previous section, we scanned our image one pixel at a time. Now we are going to use the two matrices you examined earlier to scan. Run the following blocks to scan your image with each of the two matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "brightness = 90\n",
    "# Run scan\n",
    "%run capture_image.py --mask H_packaged.npy --out sensor_readingsH --width 32 --height 32 --brightness 90\n",
    "\n",
    "sr = np.load('sensor_readingsH_%s_0.npy' % str(brightness))\n",
    "# Estimate the offset\n",
    "oest_H, s_H = getOffsetEstimateAndS(sWithOffsetCalibration = sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Let's reconstruct your image. Based off of your simulation results, is this the reconstruction quality that you expected using `H`? Think about how noisy our actual imaging system is.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = np.load('H.npy')\n",
    "\n",
    "idealReconstruction(H = H, matrixName = 'H', s = s_H - oest_H, realImaging = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As expected, the randomly generated H matrix does not work well, if at all.**\n",
    "\n",
    "Next, let's try to image your index card using `mysteryH`. Imaging with `mysteryH` requires some additional pre-processing to stitch sensor readings (associated with the mask that we split) back together. This has been taken care of for you in the code below. \n",
    "\n",
    "**<span style=\"color:red\">Run the following code block. It will capture sensor readings using the mystery matrix `mysteryH`. Select the COM port associated with UART1 and the 1280x720 projector screen.</span>**\n",
    "\n",
    "*Note: Don't worry about this error message: \"`Incomplete measurement row. Is your mask matrix size correct? Padding outputs 31 times for display.`\" IF it states that outputs are padded exactly 31 times. This is due to the fact that `mysteryH`'s row 0 is split.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run scripts/helpers.py\n",
    "%matplotlib inline\n",
    "brightness = 90\n",
    "# Run scan\n",
    "%run capture_image.py --mask mysteryH_packaged.npy --out sensor_readingsmysteryH --width 32 --height 32 --brightness 90\n",
    "\n",
    "# PREPROCESSING -------------------------------------------------------------------\n",
    "\n",
    "sr = np.load('sensor_readingsmysteryH_%s_0.npy' % str(brightness))\n",
    "# Estimate the offset\n",
    "oest_mysteryH, sRow0Split = getOffsetEstimateAndS(sWithOffsetCalibration = sr)\n",
    "# Combine rows 0a, 0b of `s` \n",
    "s_mysteryH = getMysteryS(sRow0Split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Let's reconstruct your image. Based off of your simulation results, is this the reconstruction quality that you expected using `mysteryH`?</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mysteryH = np.load('mysteryH.npy')\n",
    "\n",
    "idealReconstruction(H = mysteryH, matrixName = 'mysteryH', s = s_mysteryH - oest_mysteryH, realImaging = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment on your reconstruction results when using `H` and `mysteryH`. In real imaging, which matrix did better? Did this match your expectations from simulation? Why? How did you expect multipixel imaging to compare to single pixel imaging from Imaging 2? What are some observed limitations of multipixel imaging?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Your Answer Here!</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='checkoff'></a>\n",
    "## Checkoff\n",
    "When you are ready to get checked off, please have each person in your group fill out the [Check Off Form](https://forms.gle/hGEDvovN9xgFinE2A). Follow the form exactly and submit. Your GSI or a Lab Assistant will come by once they are available and go through some checkoff questions with your group. Do not take apart your setup before being checked off."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
