{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Lab 2: Single Pixel Scanning\n",
    "\n",
    "### EECS 16A: Designing Information Devices and Systems I, Fall 2021\n",
    "<!--- Lily Bhattacharjee (lbhattacharjee@berkeley.edu)\n",
    "      Wahid Rahman (wahid.rahman@berkeley.edu)\n",
    "      Leyla Kabuli (lakabuli@berkeley.edu)\n",
    "      Raghav Gupta (raghav.tech13@berkeley.edu)\n",
    "---->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Instructions](#instructions)\n",
    "* [Lab Policies](#policies)\n",
    "* [Overview](#overview)\n",
    "* [Task 1: Images, Vectors, and Matrices](#images)\n",
    "    * [Task 1a: Working with Images](#task2a)\n",
    "    * [Task 1b: Scanning Mask Matrix](#task2b)\n",
    "* [Task 2: Imaging Real Pictures](#task3)\n",
    "* [Checkoff](#checkoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='instructions'></a>\n",
    "## Instructions\n",
    "\n",
    "* **Gently disinfect all commonly touched surfaces** at your lab station using the provided cleaning wipes.\n",
    "\n",
    "* Complete this lab by filling in all of the required sections, marked with `\"YOUR CODE HERE\"` or `\"YOUR COMMENTS HERE\"`.\n",
    "\n",
    "\n",
    "* When you finish, submit a checkoff request to get checked off for this lab. Be ready to answer a few questions to show your understanding of each section.\n",
    "\n",
    "\n",
    "* Labs will be graded based on completion for teams of 2 students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='policies'></a>\n",
    "## Lab Policies\n",
    "* **YOU MUST ATTEND THE LAB SECTION YOU ARE ENROLLED IN. If you anticipate missing a section, please notify your GSI in advance.**\n",
    "* **You are required to return all parts checked out at the beginning of the lab section unless told otherwise.**\n",
    "* **You are free to stay for the full allotted time and hack around with the lab equipment, but please reserve the GSI's time for lab-related questions.**\n",
    "* **Food and drinks are not allowed in the lab.** \n",
    "* **Clean up, turn off all equipment, and log off of computers before leaving.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='overview'><span style='color:blue'>Overview</span></a>\n",
    "<center>\n",
    "<img src=\"images/system_diagram.svg\" style=\"height:256px\" />\n",
    "</center>\n",
    "This week, you will scan a real-life image pixel-by-pixel using a projector and light sensor circuit (a.k.a. **single pixel camera**) and write code in your Jupyter notebook to display the captured image. \n",
    "\n",
    "You will begin by checking that the circuit you built last time (with minor modifications) works and that the projector is properly connected to the computer. \n",
    "\n",
    "Next, you will write code to generate the \"mask\" patterns that the projector uses to scan the object. \n",
    "\n",
    "Then, you will use your generated mask matrix to photograph an image with the projector and ambient light sensor setup (seen below). Finally, you will write code to recreate the image from light sensor readings that are sent to your computer via the Launchpad.\n",
    "\n",
    "To prevent room lighting from affecting these measurements, the projector setup is usually placed in a closed cardboard box. \n",
    "\n",
    "<br><br>\n",
    "<center>\n",
    "**Cory 140 Setup**\n",
    "<img src=\"images/side.png\" style=\"height:350px\" />\n",
    "<br>\n",
    "**Cory 125 Setup**\n",
    "<img src=\"images/125_setup.jpg\" style=\"height:350px\" />\n",
    "</center>\n",
    "\n",
    "The single pixel imaging process would involve the following steps:\n",
    "<ul>\n",
    "    <li> The projector illuminates the object with a mask. </li>\n",
    "    <li> The ambient light sensor detects the total amount of light reflected off the object. More light leads to more current through the sensor. </li>\n",
    "    <li> The analog circuit converts the sensor's current into an output voltage. More light $\\rightarrow$ higher sensor current $\\rightarrow$ higher output voltage. </li>\n",
    "    <li> This analog voltage is converted into a digital brightness value. </li>\n",
    "</ul>    \n",
    "\n",
    "<b>Note:</b> In the real world, we come across random irregular fluctuations while taking measurements. This is called noise. It is important to consider noise while designing any system, and this lab is no different. You will learn more about noisy imaging in the Imaging 3 lab.\n",
    "</font>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%run scripts/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='images'></a>\n",
    "# <span style='color:blue'>Task 1: Images, Vectors, and Matrices </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2a'></a>\n",
    "## <span style=\"color:blue\">Task 1a: Working with Images</span>\n",
    "\n",
    "<br>\n",
    "    \n",
    "How can we represent an image? Consider a 5x5 grayscale image, where each of the 25 pixel intensities vary in shades of gray. One way to represent this is with a 2D matrix (2D NumPy array). The values stored in this array, varying from 0 to 1, correspond to different shades of gray: the lower the pixel value, the darker the pixel.  \n",
    "\n",
    "For example, take the 5x5 **`gradient_image`** shown below. Starting from the top-left pixel (pixel[0,0]), each pixel becomes progressively brighter as you traverse the image row-by-row. Note that we will be using 0 indexing in lab as most programming languages (including Python) index in lists starting from 0.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/gradient.JPG\" align=\"center\" style=\"height:200px\" />\n",
    "<figcaption>Gradient image example</figcaption>\n",
    "</center>\n",
    "\n",
    "We can create this in Python using a $5 \\times 5$ NumPy 2D array called **`gradient_image`** with *linearly-spaced* floating point values from 0 to 1. The Python code to generate this is provided for you below. Take a look at the numerical 2D array and the corresponding image that is displayed by using the `imshow` function.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 5x5 gradient image with values from 0 to 1.\n",
    "gradient_image = np.linspace(0, 1, 25).reshape([5, 5])\n",
    "\n",
    "print(gradient_image)\n",
    "plt.imshow(gradient_image, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What color does 1.0 correspond to? What about 0?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR COMMENTS HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of treating our images as 2D matrices, we can \"reshape\" or \"flatten\" our images into 1-D vectors. That is, instead of having a $5 \\times 5$ matrix for our image, we can represent it using a $25 \\times 1$ vector. This makes it simpler for us to use the linear algebra techniques learned in class for image processing. \n",
    "    \n",
    "Let's look at the 3x3 example image below (colored for illustrative purposes). How can we transform this 2D vector matrix into a 1-D column vector? \n",
    "    \n",
    "Essentially, the $0$th row is flipped on its side (rotate clockwise 90 degrees), such that its left-most element is on top and its right-most element is on the bottom. The $1$st row is also flipped on its side in the same way and appended below. These steps are repeated for each subsequent row of the original 2D image until you build a $9 \\times 1$ **column vector**.    \n",
    "\n",
    "<center>\n",
    "<img src=\"images/matrix_to_col_new.png\" style=\"width:500px\"/>\n",
    "</center>\n",
    "\n",
    "Mathematically, each pixel value in the $3 \\times 3$ image is represented as a variable $p_{ij}$, where $i$ is the row and $j$ is the column associated with the pixel location. This same image represented as a 1-D column vector (called $\\vec{i}$) is:\n",
    "\n",
    "$$\\vec{i} = \\begin{bmatrix} p_{00} \\\\ p_{01} \\\\ p_{02} \\\\ p_{10} \\\\ p_{11} \\\\ p_{12} \\\\ p_{20} \\\\ p_{21} \\\\ p_{22} \\end{bmatrix}$$    \n",
    "    \n",
    "The procedure described above can be used to convert any $N \\times M$ 2D image into a `num_pixels` $\\times 1$ **column vector**, where `num_pixels` $= N \\times M$.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Convert the 5x5 `gradient_image` that you created above into a 25x1 column vector `gradient_image_vector` and display it. You will find the command `np.reshape` helpful. What pattern do you notice? Think about why you see this pattern.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert the 5x5 matrix into a 25x1 column vector\n",
    "gradient_image_vector = # YOUR CODE HERE\n",
    "\n",
    "# Display the vector\n",
    "plt.imshow(gradient_image_vector, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task2b'></a>\n",
    "## <span style=\"color:blue\">Task 1b: Scanning Mask Matrix</span>\n",
    "\n",
    "Next, we will create a \"mask\" matrix (array) to enable our simulated projector to illuminate and scan individual pixels, one at a time. This is the magic behind our virtual single pixel camera. \n",
    "\n",
    "If **`gradient_image_vector`** is represented by the column vector variable $\\vec{i}$, the act of transforming $\\vec{i}$ by a matrix $H$ into another 1D column vector $\\vec{s}$ is represented mathematically as:\n",
    "\n",
    "$$ \\vec{s} = H \\vec{i} $$\n",
    "\n",
    "This matrix multiplication represents what happens when we scan an image with our virtual single pixel camera! In the context of a real-world imaging system, $H$ represents the scanning \"mask matrix,\" whose rows are projected one-by-one onto the image we want to scan. $\\vec{s}$ represents digitized readings from the analog circuit's light sensor. In the context of the simulation, each mask in $H$ will be reshaped to match the dimensions of the image, and subsequently overlaid one at a time, with only illuminated pixel measurements contributing to the corresponding mask measurement. Each element $s_k$ of $\\vec{s}$ corresponds to one scan (using one row $k$ of $H$, that we refer to as $H_k$). \n",
    "\n",
    "Each 1D **row of $H$** represents a **mask**. But what is a mask? In the context of our virtual single pixel camera, a mask is a way to highlight certain locations in the image while hiding others during scanning. For a 3x4 image (where 3 = height, 4 = width), a mask taken from **row 0 of $H$** is represented as the $1 \\times 12$ row vector below: \n",
    "\n",
    "$$\n",
    "H_0 \n",
    "= \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "However, the mask must first be converted into its 2D form, as shown below, before it's projected over the 2D image. The mask exposes only the top-left pixel of the 2D image and hides all other pixels. Note that you can convert a 2D mask into a 1D row of $H$ by appending each of the 2D mask's rows to the right of the previous row.\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/black_hite.png\" style=\"width:400px\"/>\n",
    "</center>\n",
    " \n",
    "To expose each pixel of the 3x4 image $\\vec{i}$ individually, we would need a 12x12 $H$ that has 12 masks (rows), each with a single white \"exposed\" pixel in a unique location. This means that **row 1 of $H$** (exposing $iv_{01}$) would look like:\n",
    "\n",
    "$$\n",
    "H_1 \n",
    "= \\begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix}\n",
    "$$\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/black_white_shifted.jpg\" style=\"width:400px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of masking an image, then uncovering one pixel at a time, and sensing the resultant ambient light performs the matrix multiplication $\\vec{s} = H \\vec{i}$ in real life. This equation implies that each element of the sensor output vector $\\vec{s}$ can be determined as:\n",
    "    \n",
    "$$s_k = H_k \\vec{i}$$\n",
    "\n",
    "Where the $k$th sensor reading is determined by the mask given by $k$th row of $H$, $H_k$. Thus, projecting the 2D representation of $H_0$ shown above onto a 3x4 image represented by the column vector $\\vec{i}$ to obtain the sensor reading $s_0$ would be mathematically equivalent to:\n",
    "\n",
    "$$\n",
    "s_0 = \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\end{bmatrix} \\vec{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">What dimensions does the mask matrix $H$ have for a 5x5 image? Why? </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR COMMENTS HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "Create the mask matrix $H$ for a 5x5 image.</span>**\n",
    "\n",
    "*Hint: Google the function `np.eye`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the mask matrix `H` for scanning a 5x5 image (be careful about the dimensions!)\n",
    "H = # YOUR CODE HERE\n",
    "\n",
    "# Test H for correctness\n",
    "test1b_H(H)\n",
    "\n",
    "# Display this matrix\n",
    "plt.imshow(H, cmap = \"gray\", interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">\n",
    "Multiply the $H$ matrix with `gradient_image_vector`. Remember to use `np.dot` to do matrix multiplication.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Multiply `H` and `gradient_image_vector`\n",
    "s = # YOUR CODE HERE\n",
    "\n",
    "# Display the result and compare it to `gradient_image_vector`\n",
    "plt.imshow(s, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Is the resultant `s` equal to `gradient_image_vector`? Why?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR COMMENTS HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when this matrix multiplication is performed? To reiterate, each row of $H$ is responsible for \"illuminating,\" or selecting, a single pixel in the gradient image. `gradient_image_vector` was created by converting the 5x5 `gradient_image` into a 1D *column vector*. Similarly, *every row* in $H$ can be represented as a 5x5 image that, in real imaging, would be projected over `gradient_image`. \n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Iterate through each row of the matrix $H$. *Reshape* each row into a 5x5 image, and check that each row illuminates a unique pixel of the original 5x5 image! Based on $ \\vec{s} = H \\vec{i} $, why are the rows of $H$ used for masking when $\\vec{i}$ is a column vector?</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through rows of matrix H and form individual masks\n",
    "plt.figure(figsize = (20, 20)) \n",
    "for k in range(25):\n",
    "    plt.subplot(5, 5, k + 1)\n",
    "    \n",
    "    mask = # YOUR CODE HERE\n",
    "    \n",
    "    plt.imshow(mask, cmap = \"gray\", interpolation = \"nearest\")\n",
    "    plt.title(\"Mask \" + str(k) + \" = Row \" + str(k) + \" of Matrix H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the images above are masks. During a single scan, we project one of these masks over our image. The white pixel illuminates a particular location on the image that we want to capture, and the black pixels obscure the other parts of the image. Thus, using the rows of $H$, we gather information one pixel at a time.\n",
    "\n",
    "Let's try to make another mask matrix, $H_{alt}$, that's a little more complicated. We want the first (upper) half of $\\vec{s}$ to contain information on every other pixel of the image (i.e. $p_{00}$, $p_{02}$, $p_{20}$...). The second (lower) half of $\\vec{s}$ should consist of information on the pixels that the first half skipped (i.e. $p_{01}$, $p_{03}$, $p_{10}$).\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Generate $H_{alt}$ for a 5x5 image whose first half (in terms of rows) illuminates every other pixel of $\\vec{i}$ and whose second half illuminates the pixels that were skipped. Multiply $H_{alt}$ by `gradient_image_vector` to produce the new output vector $\\vec{s}_{alt}$.\n",
    "</span>**\n",
    "\n",
    "<b>Hint</b>: Try to use rows from the existing H matrix. The syntax to slice an NumPy array is as follows `array[star_row:stop_row:skip,start_col:stop_col:skip]`. `np.vstack` may be very helpful (try Googling it). If done well, the code to generate H_alt should only be 1 short line.\n",
    "\n",
    "<b>Hint 2</b>: Here's how $H_{alt}$ would look for an image of size 4x4.\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/H_alt_4x4.png\" style=\"width:300px\"/>\n",
    "    <figcaption>$H_{alt}$ for a 4x4 image</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the new mask matrix `H_alt` for a 5x5 image\n",
    "H_alt = # YOUR CODE HERE\n",
    "\n",
    "# Test H_alt for correctness\n",
    "test1b_H_alt(H_alt)\n",
    "\n",
    "# Display `H_alt`\n",
    "plt.figure()\n",
    "plt.imshow(H_alt, cmap = \"gray\", interpolation = \"nearest\")\n",
    "\n",
    "# TODO: Multiply `H_alt` and `gradient_image_vector`\n",
    "s_alt = # YOUR CODE HERE\n",
    "\n",
    "# Display the result `s` and compare to `gradient_image_vector`\n",
    "plt.figure()\n",
    "plt.imshow(s_alt, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how we designed `H_alt`, `s_alt` is clearly different from `gradient_image_vector`. Each pixel of `gradient_image_vector` is still illuminated only once by `H_alt`, but the order in which the pixels are illuminated has changed. Therefore, we say that `s_alt` is a \"scrambled\" version of `gradient_image_vector`. How could we \"reconstruct\" $\\vec{s}_{alt}$ back into the original `gradient_image_vector`? \n",
    "\n",
    "Recall that our original matrix $H$ was actually the **identity matrix** $I_n$. In other words, the original $\\vec{s}$ was computed as:\n",
    "\n",
    "$ \\vec{s} = H \\vec{i} = I_n \\vec{i}$\n",
    "\n",
    "<br />    \n",
    "Using the alternate mask, $H_{alt}$, we compute the alternate output $\\vec{s}_{alt}$ as:\n",
    "\n",
    "$ \\vec{s}_{alt} = H_{alt} \\vec{i} $\n",
    "\n",
    "To \"reconstruct\" $\\vec{s}_{alt}$ back into the original `gradient_image_vector` (i.e. $\\vec{i}$), we must find a matrix $M$ that multiplies $\\vec{s}_{alt}$ to make the following true:\n",
    "\n",
    "$ M \\vec{s}_{alt} = \\vec{i} $\n",
    "\n",
    "i.e.\n",
    "\n",
    "$ M H_{alt} \\vec{i} = \\vec{i} $\n",
    "\n",
    "**<span style=\"color:red\">What should M be to recover $\\vec{i}$?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`YOUR COMMENTS HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Write code to reconstruct `gradient_image_vector` from `s_alt`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reconstruct `gradient_image_vector`\n",
    "M = # YOUR CODE HERE\n",
    "gradient_image_vector_reconstruct = # YOUR CODE HERE\n",
    "\n",
    "# Display M\n",
    "plt.figure()\n",
    "plt.imshow(M, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title(\"M\")\n",
    "plt.show()\n",
    "\n",
    "# Display M*H_alt\n",
    "plt.figure()\n",
    "plt.imshow(np.dot(M,H_alt), cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.title(\"M*H_alt\")\n",
    "plt.show()\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(gradient_image_vector_reconstruct, cmap = \"gray\", interpolation = \"nearest\")\n",
    "plt.xticks([])\n",
    "plt.yticks(np.arange(0, 30, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='task3'></a>\n",
    "## <span style=\"color:blue\">Imaging Real Pictures</span>\n",
    "\n",
    "Finally, we will use our two matrices to image a real picture. Because our picture is fairly large, we want each individual mask to have dimensions 30x40 (i.e. height = 30, width = 40) to match the 4:3 (W:H) aspect ratio of the projector. Think about how big the mask matrix was for the 5x5 example. How big must it be for a 30x40 picture?\n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Recreate both the $H$ and $H_{Alt}$ masks to match these new dimensions. </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate `H`\n",
    "H = # YOUR CODE HERE\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(H, cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recreate `H_Alt`      \n",
    "H_Alt = # YOUR CODE HERE\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(H_Alt, cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the two matrices we made are invertible and the correct size. Run the code block below to invert the matrices and test dimensions - if any of the lines fail, it means the code used to generate either matrix resulted in a incorrect size or non-invertible, linearly dependent matrix, which is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_masks_img2(H, H_Alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mask matrices must be saved as files before they can be used to perform real imaging. The files are read by our imaging script, as seen below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Run the cell below to save `H` and `H_Alt`!</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('H.npy', H)\n",
    "np.save('H_Alt.npy', H_Alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:red\">**IMPORTANT**</span>: <a id ='setup'><span style = \"color: blue\">Hardware Setup</span></a>\n",
    "\n",
    "# Please follow instructions here ( [Cory 140](ee16a_imaging_setup_140.pdf) [Cory 125](ee16a_imaging_setup_125.pdf) ) *verbatim* to get consistent results. Having a good setup will make taking the picture much easier and cleaner! The cardboard box can be found in the top left of your station.\n",
    "\n",
    "\n",
    "\n",
    "## Once you are done with the setup, call over either a TA or an ASE to have them check over your setup to make sure it is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need an object to take a picture of. There are index cards and markers at the GSI desk; **<span style=\"color:red\">take an index card and draw something on its blank (no lines) side. Place this index card inside the box so that the projector can project onto it</span>** (see the Overview image). \n",
    "\n",
    "**<span style=\"color:green\">Cory 140 Setup</span>**: Insert the index card into the slot at the far end of the stand. As in the setup instructions linked above, place your index card so that your image is upside down. This will ensure that the scan will end up right side up, since your projector is also placed upside down.\n",
    "\n",
    "**<span style=\"color:blue\">Cory 125 Setup</span>**: You'll need to tape the index card to the side of the box that the projector is projecting onto. \n",
    "\n",
    "Tape is on the TA desk; do not take the whole dispenser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Double check that you've done the following before proceeding:</span>**\n",
    "\n",
    "* Upload `AnalogReadSerial` to the Launchpad.\n",
    "\n",
    "* Close out of the Energia Serial Monitor.\n",
    "\n",
    "* Make sure that the ambient light sensor is aimed at the center of the index card! The legs should not be touching.\n",
    "\n",
    "* Seal the imaging system inside the box to keep ambient light out during scanning. If the holes for cables are too big, try to have them face a solid, unmoving object that can block out light."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">You will then run the `capture_image.py` script below that projects mask patterns onto your image based on the $H$ matrix that you designate. This script controls the scanning process.</span>** \n",
    "\n",
    "In the code block below, the `--mask` tag points to the file (including the npy extension) associated with the mask matrix you want to use. The `--out` tag tells the script where you want to save the column vector sensor data. (The \"out\" file name doesn't include the npy extension, as it's automatically appended. Additionally, info about the capture settings, like projector brightness, is also appended to the file name. We'll take care of this for you.)\n",
    "\n",
    "When running **`capture_image.py`**, a new icon shaped like a white web will appear in the taskbar. The window depicting our masks will appear on the projector's screen. *You can confirm this by looking into the box. (Don't forget to close the box when you're done checking!)*\n",
    "\n",
    "Before scanning, you will be prompted to specify the **COM port used by the Launchpad and the display associated with the projector.** \n",
    "\n",
    "**Select the COM port associated with UART1 (previously accessed in the Energia Serial Monitor and found using the Device Manager) and the 1280x720 projector screen.** Note that you want to specify the index of your choice i.e. for `2) 1280 x 720`, specify 2. **<span style=\"color:red\">Make sure that you selected the correct COM port!</span>**\n",
    "\n",
    "`capture_image.py` iterates over the rows of the $H$ matrix you made. These rows are translated, one-by-one, into real masks projected onto the screen. Light sensor readings are taken for each mask. At the start of the scan, you'll see a series of `Loc: # Data: #` printed to the output below. `Loc` corresponds to the index $k$ of the current sensor reading (and likewise current row of H). `Data` corresponds to the actual digitized value obtained from the light sensor. This \"debug\" information is printed consecutively for the first few/last few sensor outputs. Otherwise, this info is printed when `k % 100 = 0` (every 100 scans). \n",
    "\n",
    "Don't worry about messages like `Time delta between captures in s: #`. This is printed a lot because the lab computers are slow. Make sure you followed the hardware setup near the beginning - restart your MSP by unplugging and replugging it in after programming it.\n",
    "\n",
    "The whole scanning process should take roughly 3 minutes. \n",
    "\n",
    "Running the code block below will start your scan - **don't** click on the window popup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (so you don't have to start from the top)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "\n",
    "%run capture_image.py --mask H.npy --out sensor_readingsH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Not getting a good picture?</span>**\n",
    "\n",
    "If you selected the incorrect COM port, a lot more \"debug\" lines will be dumped. You might notice `Data: -1` or `Losing data! Consider increasing your timeout!` messages. Once you see these messages, **stop** running that code block, **save** your Jupyter notebook, then **close the ipython notebook in terminal (Ctrl+C twice) and re-open it** (alternately, you can save and restart your kernel). You'll lose any saved variables (not output images), but everything you need has been saved to a file. Rerun the following code block again, but **make sure you select the right COM port**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sensor readings have been captured, load the sensor reading vector into the cell below. Once again, here is the equation relating $H$, the sensor reading column vector $\\vec{s}$, and the image column vector $\\vec{i}$:\n",
    "\n",
    "$$\\vec{s} = H \\vec{i}$$\n",
    "\n",
    "**<span style=\"color:red\">Recreate the image from the sensor readings obtained with `H`.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load('sensor_readingsH_100_0.npy')\n",
    "H = np.load('H.npy')\n",
    "\n",
    "# TODO: Create the image vector from `H` and `sr`\n",
    "# Hint: Because `H` is a special matrix, technically you do not need to perform any matrix operations\n",
    "iv = # YOUR CODE HERE \n",
    "\n",
    "img = np.reshape(iv, (30, 40))\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.imshow(img, cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have imaged your first image using your single pixel camera! \n",
    "\n",
    "**<span style=\"color:red\">\n",
    "Does your recreated image match the real image? What are some problems you notice? \n",
    "</span>**\n",
    "\n",
    "Here is an example of a picture we took using this setup:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/ee16a_picture.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Next, use the second mask `H_Alt` for imaging. Can you repeat the same reconstruction procedure just by replacing $H$ with $H_{Alt}$? Why or why not?</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `capture_image.py` again (taking the same precautions as above) to collect sensor readings. Make sure to run it from the code block below to point the script to `H_Alt`. Then reconstruct the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (so you don't have to start from the top)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "\n",
    "%run capture_image.py --mask H_Alt.npy --out sensor_readingsHAlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor readings\n",
    "sr = np.load('sensor_readingsHAlt_100_0.npy')\n",
    "H_Alt = np.load('H_Alt.npy')\n",
    "\n",
    "# TODO: Create the image vector from `H_Alt` and `sr`\n",
    "# Hint: You need to perform a matrix operation before multiplying\n",
    "iv = # YOUR CODE HERE \n",
    "\n",
    "img = np.reshape(iv, (30, 40))\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.imshow(img, cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are done for the week! Save your code and circuit for next lab, where you will illuminate multiple pixels per mask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<span style=\"color:red\"> Do not take apart your setup before being checked off. </span>** \n",
    "**Afterwards, you may take the Launchpad and circuit kit with you. Remember to bring it back next week!**\n",
    "\n",
    "<a id='checkoff'></a>\n",
    "## Checkoff\n",
    "When you are ready to get checked off,\n",
    "1. Fill out the checkoff google form. **[Checkoff Form](https://docs.google.com/forms/d/e/1FAIpQLSeq9w_gvQKS37hUXgTDtiYhu9gNmu5OFzglIYAF4nfXQc5mOA/viewform?usp=sf_link)**\n",
    "2. Submit a **checkoff** request on the lab queue. **[Checkoff queue](https://lab.eecs16a.org)** Only one person from your group should submit the queue request, but everyone must submit their own google form. \n",
    "\n",
    "Your GSI or a Lab Assistant will join you when they are available and go through some checkoff questions with your group. They will go through the checkoff list in order. Please be patient!\n",
    "\n",
    "\n",
    "#### Post-checkoff Clean Up: (this applies to each week's lab)\n",
    "1. Pack away your launchpad and lab kit materials to bring home  - make a note to bring them back next week!\n",
    "2. Throw away any trash at your station\n",
    "3. Return the wires from the back walls\n",
    "4. SIGN OUT of the computers - DO NOT SHUT DOWN\n",
    "5. Check that other machines at your lab station are powered off"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
